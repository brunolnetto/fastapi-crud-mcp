[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green)](LICENSE)

# FastAPI CRUD MCP

A minimal CRUD API for â€œitems,â€ built with FastAPI and exposed as MCP tools via FastAPI-MCP. Includes a scenario-driven client harness using PydanticAI and Rich.

---

## ğŸš€ Features

- **FastAPI**: high-performance HTTP API  
- **SQLAlchemy + Pydantic**: ORM models + input/output schemas  
- **FastAPI-MCP**: auto-expose your endpoints as MCP tools (`/mcp/tools`, `/mcp/events`)  
- **Rich CLI**: beautiful, colored terminal output for scenario runs  
- **Scenario Runner**: client harness that drives and validates your API via PydanticAI agents  
- **SQLite backend** for demo; easily swap to PostgreSQL, MySQL, etc.

---

## ğŸ“¦ Project Layout

```

.
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ server
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI + FastAPI-MCP wiring
â”‚   â”‚   â”œâ”€â”€ models.py          # SQLAlchemy + Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routes.py          # CRUD endpoints
â”‚   â”‚   â”œâ”€â”€ crud.py            # DB operations
â”‚   â”‚   â”œâ”€â”€ db.py              # session & engine
â”‚   â”‚   â””â”€â”€ logger.py          # stdlib logging setup
â”‚   â””â”€â”€ client
â”‚       â”œâ”€â”€ scenarios.py       # Scenario definitions
â”‚       â””â”€â”€ main.py            # run\_scenarios.py harness
â”œâ”€â”€ .env                       # example environment variables
â”œâ”€â”€ pyproject.toml             # Project dependencies
â””â”€â”€ README.md                  # this file

````

---

## âš™ï¸ Installation & Setup

1. **Clone & enter directory**  
   ```bash
   git clone https://github.com/yourusername/fastapi-crud-mcp.git
   cd fastapi-crud-mcp
   ```

2. **Create & activate a virtualenv**

   ```bash
   uv venv
   source .venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   uv sync
   ```

4. **Environment variables**
   Copy the example and adjust if needed:

   ```bash
   cp .env.example .env
   ```

   ```env
   MCP_HOST_URL='http://127.0.0.1:8000/mcp'

   LLM_PROVIDER='openai'
   LLM_MODEL_NAME='gpt-4o-mini'
   LLM_MODEL=${LLM_PROVIDER}:${LLM_MODEL_NAME}

   OPENAI_API_KEY=sk-proj-your-api-key-here
   ```

---

## ğŸƒ Running the Server

```bash
docker compose up -d --build
```

* **API docs** â†’ `http://localhost:8000/docs`
* **OpenAPI JSON** â†’ `http://localhost:8000/openapi.json`

---

## ğŸ¤– Running the Scenario Client

```bash
python3 -m backend.client.main
```

This harness will:

1. Load your `.env` settings
2. Spin up a PydanticAI agent against `MCP_HOST_URL`
3. Execute each scenario (create/list/get/update/delete)
4. Display rich panels for prompts & outputs

---

## ğŸš¨ Notes & Tips

* **Switch DB**: edit `backend/server/db.py` for PostgreSQL or MySQL.
* **Add auth**: protect `/mcp` or `/api` via FastAPI dependencies.
* **Extend scenarios**: drop new entries into `backend/client/scenarios.py`.
* **Production**: add Alembic for migrations, and monitor with Prometheus.

---

## ğŸ¤ Contributing

1. Fork ğŸ”±
2. Create a feature branch:

   ```bash
   git checkout -b feature/my-feature
   ```
3. Commit & push:

   ```bash
   git commit -am "Add awesome feature"
   git push origin feature/my-feature
   ```
4. Open a PR and weâ€™ll review!

---

## ğŸ“„ License

This project is MIT-licensedâ€”see the [LICENSE](LICENSE) file for details.
